{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-14f4d72dba84>:13: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  lat = nc.variables['lat'][54:]\n",
      "<ipython-input-9-14f4d72dba84>:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  lon = nc.variables['lon'][:]\n",
      "<ipython-input-9-14f4d72dba84>:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  var = nc.variables[var_name][:]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-14f4d72dba84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marea\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ATLANTIC\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.07\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSIGMA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_ITER\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Change \"ATLANTIC\" or \"ARCTIC\" here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-14f4d72dba84>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(area, LR, SIGMA, NUM_ITER)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;31m# Plot clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[0mplot_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;31m# Calculate metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-14f4d72dba84>\u001b[0m in \u001b[0;36mplot_clusters\u001b[1;34m(data, lat, lon, clusters, output_dir, area)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;31m# Calculate the mean for the current cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0msoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcluster_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# Define levels and boundaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, indx)\u001b[0m\n\u001b[0;32m   3220\u001b[0m         \u001b[1;31m# mask of being reshaped if it hasn't been set up properly yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3221\u001b[0m         \u001b[1;31m# So it's easier to stick to the current version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3222\u001b[1;33m         \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3223\u001b[0m         \u001b[0m_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile\n",
    "from minisom import MiniSom\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def load_data(path, var_name,area):\n",
    "    nc = NetCDFFile(path)\n",
    "    # Load the variable of interest\n",
    "    if area==\"ATLANTIC\":\n",
    "        lat = nc.variables['lat'][54:]\n",
    "        lon = nc.variables['lon'][:]\n",
    "        reduced_lon = lon[:80]\n",
    "        lon = np.concatenate((reduced_lon, lon[-80:]), axis=0)\n",
    "        \n",
    "        var = nc.variables[var_name][:] \n",
    "        reduced_var = var[:, :54, :80]\n",
    "        var = np.concatenate((reduced_var, var[:, :54, -80:]), axis=2)\n",
    "    elif area==\"ARCTIC\":\n",
    "        lat = nc.variables['lat'][:28]\n",
    "        lon = nc.variables['lon'][:]\n",
    "        var = nc.variables[var_name][:] # zonal wind\n",
    "        var = var[:, :28, :]\n",
    "    return var, lat, lon\n",
    "\n",
    "def train_som(data, lr, sigma, num_iter):\n",
    "    # Normalize data\n",
    "    flattened_data = data.reshape(data.shape[0], -1)\n",
    "    data_normalized = (flattened_data - flattened_data.min()) / (flattened_data.max() - flattened_data.min())\n",
    "    \n",
    "    # Initialize the SOM\n",
    "    som = MiniSom(5, 1, data_normalized.shape[1], sigma=sigma, learning_rate=lr)\n",
    "\n",
    "    # Initialize weights randomly\n",
    "    som.random_weights_init(data_normalized)\n",
    "\n",
    "    # Train the SOM\n",
    "    som.train_random(data_normalized, num_iter)\n",
    "    \n",
    "    return som, data_normalized\n",
    "\n",
    "def cluster_data(data, som):\n",
    "    # Find the best-matching unit (BMU) for each data point\n",
    "    bmus = np.array([som.winner(d) for d in data])\n",
    "    \n",
    "    # Create a dictionary to map BMUs to data points\n",
    "    bmu_to_data = {}\n",
    "    for i, bmu in enumerate(bmus):\n",
    "        bmu_tuple = tuple(bmu)  # Convert NumPy array to tuple\n",
    "        if bmu_tuple not in bmu_to_data:\n",
    "            bmu_to_data[bmu_tuple] = []\n",
    "        bmu_to_data[bmu_tuple].append(i)\n",
    "\n",
    "    # Convert the dictionary values (lists of data indices) to clusters\n",
    "    clusters = list(bmu_to_data.values())\n",
    "    return clusters, bmus\n",
    "\n",
    "def plot_clusters(data, lat, lon, clusters, output_dir, area):\n",
    "    lons, lats = np.meshgrid(lon, lat)\n",
    "    cluster_numbers = range(len(clusters))\n",
    "\n",
    "    for cluster_number in cluster_numbers:\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        if area == \"ATLANTIC\":\n",
    "            map = Basemap(projection='npstere', boundinglat=30, lon_0=0, llcrnrlon=-90, urcrnrlon=90)\n",
    "        elif area == \"ARCTIC\":\n",
    "            map = Basemap(projection='npstere', boundinglat=60, lon_0=0, llcrnrlon=-90, urcrnrlon=90)\n",
    "        FONTSIZE = 18\n",
    "\n",
    "        # Create a filter for the current cluster number\n",
    "        cluster_filter = [x == cluster_number for x in range(len(data))]\n",
    "        \n",
    "        # Calculate the mean for the current cluster\n",
    "        soms = np.mean(data[cluster_filter, :, :], axis=0)\n",
    "\n",
    "        # Define levels and boundaries\n",
    "        levels = np.array([-15, -10, -7, -5, -3, -1, 1, 3, 5, 7, 10, 15])\n",
    "\n",
    "        # Create the contour plot\n",
    "        variable = map.contourf(lons, lats, soms, cmap=\"seismic\", levels=levels, zorder=5, extend='both')\n",
    "        cb = map.colorbar(variable, \"bottom\", size=\"3%\", pad=\"3%\", ticks=levels)\n",
    "\n",
    "        # Customize the colorbar\n",
    "        for t in cb.ax.get_xticklabels():\n",
    "            t.set_fontsize(18)\n",
    "        cb.set_ticklabels(levels)\n",
    "\n",
    "        # Customize the plot title and labels\n",
    "        plt.title(f'SOMS Cluster {cluster_number}')\n",
    "        cb.set_label('slp [hPa]', fontsize=18)\n",
    "\n",
    "        # Draw coastlines and countries\n",
    "        map.drawcoastlines(linewidth=0.3, zorder=6)\n",
    "        map.drawcountries(linewidth=0.1, zorder=7)\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(f'{output_dir}/SOMS_cluster_{cluster_number}_{area}.png', dpi=300)\n",
    "\n",
    "def calculate_metrics(data_normalized, bmus):\n",
    "    # Calculate Silhouette Score using BMUs as cluster labels\n",
    "    pairwise_distances_matrix = pairwise_distances(data_normalized)\n",
    "    silhouette_avg = silhouette_score(pairwise_distances_matrix, bmus.argmin(axis=1))\n",
    "    \n",
    "    # Calculate Dunn Index\n",
    "    def dunn_index(cluster_arrays):\n",
    "        min_intercluster_distances = float('inf')\n",
    "        max_intracluster_diameter = 0.0\n",
    "\n",
    "        for cluster1 in cluster_arrays:\n",
    "            for cluster2 in cluster_arrays:\n",
    "                if cluster1 is not cluster2:\n",
    "                    # Calculate the minimum inter-cluster distance\n",
    "                    intercluster_distance = pairwise_distances(cluster1, cluster2, metric='euclidean').min()\n",
    "                    if intercluster_distance < min_intercluster_distances:\n",
    "                        min_intercluster_distances = intercluster_distance\n",
    "\n",
    "            # Calculate the maximum intra-cluster diameter\n",
    "            intracluster_diameter = euclidean(cluster1.max(axis=0), cluster1.min(axis=0))\n",
    "            if intracluster_diameter > max_intracluster_diameter:\n",
    "                max_intracluster_diameter = intracluster_diameter\n",
    "\n",
    "        return min_intercluster_distances / max_intracluster_diameter\n",
    "\n",
    "    dunn = dunn_index(cluster_arrays)\n",
    "    \n",
    "    return silhouette_avg, dunn\n",
    "\n",
    "def main(area,LR,SIGMA,NUM_ITER):\n",
    "    # Set your parameters\n",
    "    lr = LR  # Learning rate\n",
    "    sigma = SIGMA  # Sigma parameter\n",
    "    num_iter = NUM_ITER  # Number of iterations\n",
    "    output_dir = 'N:/atm_glomod/user/jomuel001/CMIP6_models/ERA5/AREA.-90_90_89.7849_29.0866/CLUSTER/PLOTS/'  # Directory to save cluster plots\n",
    "    \n",
    "    # Load data\n",
    "    if area == \"ATLANTIC\":\n",
    "        path = 'N:/atm_glomod/user/jomuel001/CMIP6_models/ERA5/slp_hpa_ERA5_1985-2014.N_mjjaso_atrbg_aacrm21_remapbnds.nc'\n",
    "    elif area == \"ARCTIC\":\n",
    "        path = 'N:/atm_glomod/user/jomuel001/CMIP6_models/ERA5/slp_hpa_ERA5_1985-2014.N_mjjaso_atrbg_aacrm21_remapbnds.nc'\n",
    "    var_name = 'MSL'\n",
    "    data, lat, lon = load_data(path, var_name,area)\n",
    "    \n",
    "    # Train SOM\n",
    "    som, data_normalized = train_som(data, lr, sigma, num_iter)\n",
    "    \n",
    "    # Cluster data\n",
    "    clusters, bmus = cluster_data(data_normalized, som)\n",
    "    \n",
    "    # Plot clusters\n",
    "    plot_clusters(data_normalized, lat, lon, clusters, output_dir, area)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    silhouette_avg, dunn = calculate_metrics(data_normalized, bmus)\n",
    "    \n",
    "    print(f\"Silhouette Score ({area}): {silhouette_avg}\")\n",
    "    print(f\"Dunn Index ({area}): {dunn}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(area=\"ATLANTIC\",LR=0.07,SIGMA=0.2,NUM_ITER=10000)  # Change \"ATLANTIC\" or \"ARCTIC\" here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
